{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyhealth Model PR\n",
    "Authors: Aditya Asthana, Krish Desai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.2.2-cp38-none-macosx_10_9_x86_64.whl (150.6 MB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.17.2-cp38-cp38-macosx_10_13_x86_64.whl (1.7 MB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.0.3-cp38-cp38-macosx_10_9_x86_64.whl (11.7 MB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.7.5-cp38-cp38-macosx_10_12_x86_64.whl (7.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.4 MB 2.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torchxrayvision\n",
      "  Downloading torchxrayvision-1.3.4-py3-none-any.whl (29.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 29.0 MB 51.6 MB/s eta 0:00:01 0:00:01\n",
      "\u001b[?25hCollecting networkx\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./cs598env/lib/python3.8/site-packages (from torch) (4.13.2)\n",
      "Collecting jinja2\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "\u001b[K     |████████████████████████████████| 134 kB 87.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sympy\n",
      "  Using cached sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "\u001b[K     |████████████████████████████████| 193 kB 35.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting filelock\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Using cached pillow-10.4.0-cp38-cp38-macosx_10_10_x86_64.whl (3.5 MB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.24.4-cp38-cp38-macosx_10_9_x86_64.whl (19.8 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./cs598env/lib/python3.8/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting tzdata>=2022.1\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[K     |████████████████████████████████| 347 kB 32.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytz>=2020.1\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[K     |████████████████████████████████| 509 kB 16.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in ./cs598env/lib/python3.8/site-packages (from matplotlib) (25.0)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.1.1-cp38-cp38-macosx_10_9_x86_64.whl (247 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.57.0-cp38-cp38-macosx_10_9_x86_64.whl (2.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3 MB 108.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.7-cp38-cp38-macosx_10_9_x86_64.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 19.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-resources>=3.2.0; python_version < \"3.10\"\n",
      "  Using cached importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./cs598env/lib/python3.8/site-packages (from matplotlib) (3.1.4)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting imageio\n",
      "  Downloading imageio-2.35.1-py3-none-any.whl (315 kB)\n",
      "\u001b[K     |████████████████████████████████| 315 kB 108.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm>=4\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 25.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests>=1\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Collecting scikit-image>=0.16\n",
      "  Downloading scikit_image-0.21.0-cp38-cp38-macosx_10_9_x86_64.whl (12.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.9 MB 91.4 MB/s eta 0:00:01    |██▊                             | 1.1 MB 91.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.1.5-cp38-cp38-macosx_10_9_x86_64.whl (14 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./cs598env/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in ./cs598env/lib/python3.8/site-packages (from importlib-resources>=3.2.0; python_version < \"3.10\"->matplotlib) (3.20.2)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.4.2-py3-none-any.whl (52 kB)\n",
      "\u001b[K     |████████████████████████████████| 52 kB 8.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "  Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "\u001b[K     |████████████████████████████████| 159 kB 37.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Collecting tifffile>=2022.8.12\n",
      "  Downloading tifffile-2023.7.10-py3-none-any.whl (220 kB)\n",
      "\u001b[K     |████████████████████████████████| 220 kB 50.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting lazy_loader>=0.2\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Collecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.4.1-cp38-cp38-macosx_10_13_x86_64.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 49.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=1.8\n",
      "  Using cached scipy-1.10.1-cp38-cp38-macosx_10_9_x86_64.whl (35.0 MB)\n",
      "Installing collected packages: networkx, MarkupSafe, jinja2, mpmath, sympy, fsspec, filelock, torch, pillow, numpy, torchvision, tzdata, pytz, pandas, contourpy, fonttools, kiwisolver, importlib-resources, cycler, matplotlib, imageio, tqdm, idna, charset-normalizer, certifi, urllib3, requests, tifffile, lazy-loader, PyWavelets, scipy, scikit-image, torchxrayvision\n",
      "Successfully installed MarkupSafe-2.1.5 PyWavelets-1.4.1 certifi-2025.4.26 charset-normalizer-3.4.2 contourpy-1.1.1 cycler-0.12.1 filelock-3.16.1 fonttools-4.57.0 fsspec-2025.3.0 idna-3.10 imageio-2.35.1 importlib-resources-6.4.5 jinja2-3.1.6 kiwisolver-1.4.7 lazy-loader-0.4 matplotlib-3.7.5 mpmath-1.3.0 networkx-3.1 numpy-1.24.4 pandas-2.0.3 pillow-10.4.0 pytz-2025.2 requests-2.32.3 scikit-image-0.21.0 scipy-1.10.1 sympy-1.13.3 tifffile-2023.7.10 torch-2.2.2 torchvision-0.17.2 torchxrayvision-1.3.4 tqdm-4.67.1 tzdata-2025.2 urllib3-2.2.3\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Users/adityaasthana/uiuc-mcs/CS598_Final_Report/cs598env/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision pandas matplotlib torchxrayvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityaasthana/uiuc-mcs/CS598_Final_Report/cs598env/lib/python3.8/site-packages/torchxrayvision/utils.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "# **Cell 2: Imports & Globals**\n",
    "# --------------------------------------------------------------\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "import torchxrayvision as xrv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paths\n",
    "IMAGE_DIR = Path(\"data_sources/images\")            # your raw scans\n",
    "MANIFEST_DIR = Path(\"outputs\")           # where CSVs will go\n",
    "MANIFEST_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Revised Cell 3: Load Pretrained Model & Preprocessor (CPU, 1-channel)**\n",
    "import torchxrayvision as xrv\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load TorchXRayVision DenseNet-121 (grayscale input)\n",
    "model = xrv.models.DenseNet(weights=\"densenet121-res224-chex\")\n",
    "model = model.eval()  # keep on CPU; no .cuda()\n",
    "\n",
    "# Preprocessing: resize → center-crop → grayscale → to-tensor → normalize\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.Grayscale(num_output_channels=1),     # ensure 1 channel :contentReference[oaicite:0]{index=0}\n",
    "    transforms.ToTensor(),                           # yields shape [1,224,224]\n",
    "    transforms.Normalize(mean=[0.485], std=[0.229]), # single-channel norms :contentReference[oaicite:1]{index=1}\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data_sources/images/00000001_000.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data_sources/images/00000001_001.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data_sources/images/00000001_002.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data_sources/images/00000002_000.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data_sources/images/00000003_000.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             image_path  label\n",
       "0  data_sources/images/00000001_000.png      1\n",
       "1  data_sources/images/00000001_001.png      1\n",
       "2  data_sources/images/00000001_002.png      1\n",
       "3  data_sources/images/00000002_000.png      1\n",
       "4  data_sources/images/00000003_000.png      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# **Revised Cell 4: Generate Pseudo-Labels (1-channel inputs)**\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "records = []\n",
    "for fname in sorted(os.listdir(IMAGE_DIR)):\n",
    "    path = IMAGE_DIR / fname\n",
    "    img = Image.open(path).convert(\"L\")                # open as grayscale :contentReference[oaicite:2]{index=2}\n",
    "    tensor = preprocess(img).unsqueeze(0)              # shape [1,1,224,224]\n",
    "    with torch.no_grad():\n",
    "        scores = model(tensor).numpy().squeeze()       # outputs [21] pathology logits\n",
    "    idx = model.pathologies.index(\"Pneumonia\")\n",
    "    prob = torch.sigmoid(torch.tensor(scores[idx])).item()\n",
    "    label = int(prob >= 0.5)\n",
    "    records.append({\"image_path\": str(path), \"label\": label})\n",
    "\n",
    "df_labels = pd.DataFrame(records)\n",
    "df_labels.to_csv(MANIFEST_DIR/\"pseudo_labels.csv\", index=False)\n",
    "df_labels.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Create Two Domains\n",
    "- **Domain A:** your original images  \n",
    "- **Domain B:** apply a consistent augmentation (brightness & blur) to simulate a second “dataset”  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.3.2-cp38-cp38-macosx_10_9_x86_64.whl (10.1 MB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in ./cs598env/lib/python3.8/site-packages (from scikit-learn) (1.24.4)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: scipy>=1.5.0 in ./cs598env/lib/python3.8/site-packages (from scikit-learn) (1.10.1)\n",
      "Collecting joblib>=1.1.1\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.3.2 threadpoolctl-3.5.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Users/adityaasthana/uiuc-mcs/CS598_Final_Report/cs598env/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# **Cell 5: Define Augmentation & Build Manifests**\n",
    "# --------------------------------------------------------------\n",
    "aug_transform = transforms.Compose([\n",
    "    transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
    "    transforms.GaussianBlur(5),\n",
    "])\n",
    "\n",
    "# prepare lists\n",
    "manifests = {\"A\": [], \"B\": []}\n",
    "\n",
    "for _, row in df_labels.iterrows():\n",
    "    path, lbl = row[\"image_path\"], row[\"label\"]\n",
    "    # Domain A record\n",
    "    manifests[\"A\"].append({\"image_path\": path, \"label\": lbl, \"domain\": 0})\n",
    "    # Domain B: save augmented copy to a temp folder\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    aug = aug_transform(img)\n",
    "    save_path = IMAGE_DIR/\"domainB\"/os.path.basename(path)\n",
    "    save_path.parent.mkdir(exist_ok=True)\n",
    "    aug.save(save_path)\n",
    "    manifests[\"B\"].append({\"image_path\": str(save_path), \"label\": lbl, \"domain\": 1})\n",
    "\n",
    "!pip install scikit-learn\n",
    "# Split each into train/val/test (80/10/10)\n",
    "from sklearn.model_selection import train_test_split\n",
    "for dom, recs in manifests.items():\n",
    "    df = pd.DataFrame(recs)\n",
    "    train, temp = train_test_split(df, stratify=df.label, test_size=0.2, random_state=0)\n",
    "    val, test = train_test_split(temp, stratify=temp.label, test_size=0.5, random_state=0)\n",
    "    train.to_csv(MANIFEST_DIR/f\"{dom}_train.csv\", index=False)\n",
    "    val.to_csv(MANIFEST_DIR/f\"{dom}_val.csv\", index=False)\n",
    "    test.to_csv(MANIFEST_DIR/f\"{dom}_test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Cell 6: Dataset Class**\n",
    "# --------------------------------------------------------------\n",
    "class ChestDataset(Dataset):\n",
    "    def __init__(self, manifest_csv, transform=None):\n",
    "        self.df = pd.read_csv(manifest_csv)\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.Resize(224),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485], std=[0.229]),\n",
    "        ])\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(row.image_path).convert(\"RGB\")\n",
    "        img = self.transform(img)\n",
    "        return img, row.label, row.domain\n",
    "\n",
    "def make_loader(dom, split, bs=32, shuffle=True):\n",
    "    path = MANIFEST_DIR/f\"{dom}_{split}.csv\"\n",
    "    return DataLoader(ChestDataset(path), batch_size=bs, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Cell 7 (CPU only): Model Factory & Training Loop**\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def make_model():\n",
    "    m = models.densenet121(pretrained=False)\n",
    "    m.classifier = nn.Linear(m.classifier.in_features, 1)\n",
    "    return m  # CPU model\n",
    "\n",
    "def train_erm(domains, max_steps=5000, lr=1e-4):\n",
    "    loaders = {d: make_loader(d, \"train\") for d in domains}\n",
    "    iters = {d: iter(loaders[d]) for d in domains}\n",
    "    model = make_model()            # CPU\n",
    "    opt = optim.Adam(model.parameters(), lr=lr)\n",
    "    crit = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        for d in domains:\n",
    "            try:\n",
    "                imgs, labs, _ = next(iters[d])\n",
    "            except StopIteration:\n",
    "                iters[d] = iter(loaders[d])\n",
    "                imgs, labs, _ = next(iters[d])\n",
    "            # no .cuda()\n",
    "            preds = model(imgs).squeeze()\n",
    "            loss = crit(preds, labs.float())\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        if (step+1) % 1000 == 0:\n",
    "            print(f\"Step {step+1}/{max_steps}\")\n",
    "    return model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs598env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
